{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa7efeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.inspection import permutation_importance\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import catboost\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbe1223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### baseline에서 catboost(cat_features 정해주고 해보기.), scaling해서 해보기\n",
    "### y_quality?\n",
    "### 0,1/2, 0/1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ee207fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2bb4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "subm = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "87a392cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRODUCT_ID  Y_Class  Y_Quality        TIMESTAMP     LINE PRODUCT_CODE  X_1  \\\n",
       "0  TRAIN_000        1   0.533433  2022-06-13 5:14  T050304         A_31  NaN   \n",
       "1  TRAIN_001        2   0.541819  2022-06-13 5:22  T050307         A_31  NaN   \n",
       "2  TRAIN_002        1   0.531267  2022-06-13 5:30  T050304         A_31  NaN   \n",
       "3  TRAIN_003        2   0.537325  2022-06-13 5:39  T050307         A_31  NaN   \n",
       "4  TRAIN_004        1   0.531590  2022-06-13 5:47  T050304         A_31  NaN   \n",
       "\n",
       "   X_2  X_3  X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
       "0  NaN  NaN  NaN  ...   39.34   40.89   32.56   34.09   77.77     NaN     NaN   \n",
       "1  NaN  NaN  NaN  ...   38.89   42.82   43.92   35.34   72.55     NaN     NaN   \n",
       "2  NaN  NaN  NaN  ...   39.19   36.65   42.47   36.53   78.35     NaN     NaN   \n",
       "3  NaN  NaN  NaN  ...   37.74   39.17   52.17   30.58   71.78     NaN     NaN   \n",
       "4  NaN  NaN  NaN  ...   38.70   41.89   46.93   33.09   76.97     NaN     NaN   \n",
       "\n",
       "   X_2873  X_2874  X_2875  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 2881 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a79dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['PRODUCT_CODE'] = train['PRODUCT_CODE'].astype('category')\n",
    "train['LINE'] = train['LINE'].astype('category')\n",
    "\n",
    "test['PRODUCT_CODE'] = test['PRODUCT_CODE'].astype('category')\n",
    "test['LINE'] = test['LINE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a8bfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 열의 유일한 값이 nan이거나 모두 같은 값인 경우 해당 열을 제외\n",
    "def remove_col(train_df, test_df):\n",
    "    for x in train_df.columns[6:]:\n",
    "        if train_df[x].nunique()==0 or (train_df[x].nunique()==1 and len(train_df[x].unique())==1): # nan 이거나 모두 같은 값인 경우\n",
    "            train_df.drop(columns=[x], inplace=True)\n",
    "            test_df.drop(columns=[x], inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30fd903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_col(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b596197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Quality'], inplace=True)\n",
    "\n",
    "test = test[train.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a62fbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train.drop(columns=['Y_Class']), train['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6689b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2862</th>\n",
       "      <th>X_2863</th>\n",
       "      <th>X_2864</th>\n",
       "      <th>X_2865</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>368.296296</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>185.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.735849</td>\n",
       "      <td>353.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.5</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.320755</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.8</td>\n",
       "      <td>384.0</td>\n",
       "      <td>369.188679</td>\n",
       "      <td>353.0</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>182.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.351852</td>\n",
       "      <td>352.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LINE PRODUCT_CODE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  ...  X_2862  \\\n",
       "0  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   189.0   \n",
       "1  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   185.6   \n",
       "2  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.5   \n",
       "3  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.8   \n",
       "4  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   182.6   \n",
       "\n",
       "   X_2863      X_2864  X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \n",
       "0   383.0  368.296296   353.0   39.34   40.89   32.56   34.09   77.77     NaN  \n",
       "1   383.0  367.735849   353.0   38.89   42.82   43.92   35.34   72.55     NaN  \n",
       "2   383.0  367.320755   353.0   39.19   36.65   42.47   36.53   78.35     NaN  \n",
       "3   384.0  369.188679   353.0   37.74   39.17   52.17   30.58   71.78     NaN  \n",
       "4   383.0  367.351852   352.0   38.70   41.89   46.93   33.09   76.97     NaN  \n",
       "\n",
       "[5 rows x 2795 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2555d",
   "metadata": {},
   "source": [
    "### catboost cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a908d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9c4025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [06:01, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5811609030761885 : [0.14285714 0.68067227 0.68067227] ~ 0.7829945233454004 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6609634746016518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6de3cb",
   "metadata": {},
   "source": [
    "### Feature & Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cca278",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c22d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "clf.fit(train_x, train_y, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=train_x.columns).sort_values(ascending=False)[:20].sort_values()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 15)\n",
    "plt.barh(feature_imp.index, feature_imp)\n",
    "plt.title('Feature_importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b9d6a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_373</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_718</th>\n",
       "      <th>X_107</th>\n",
       "      <th>X_1010</th>\n",
       "      <th>...</th>\n",
       "      <th>X_1156</th>\n",
       "      <th>X_981</th>\n",
       "      <th>X_1974</th>\n",
       "      <th>X_451</th>\n",
       "      <th>X_531</th>\n",
       "      <th>X_727</th>\n",
       "      <th>X_1555</th>\n",
       "      <th>X_1530</th>\n",
       "      <th>X_2075</th>\n",
       "      <th>X_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.24</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614057</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.535484</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.24</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.743548</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.012903</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.24</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.322222</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.351613</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>16.967742</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.08</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.974194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.08</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>10.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>18.633333</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>18.266667</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_248  X_258      X_932   X_73  X_373  X_318     X_835      X_718  \\\n",
       "0      NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "1      NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "2      NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "3      NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "4      NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "..     ...    ...        ...    ...    ...    ...       ...        ...   \n",
       "593    NaN    NaN  13.351613  10.09    NaN    NaN  9.096774  16.967742   \n",
       "594    NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "595    NaN    NaN        NaN    NaN    NaN    NaN       NaN        NaN   \n",
       "596    NaN    NaN  13.406667  10.22    NaN    NaN  9.533333  18.633333   \n",
       "597    NaN    NaN  13.380000  10.09    NaN    NaN  9.033333  18.266667   \n",
       "\n",
       "        X_107  X_1010  ...  X_1156  X_981    X_1974  X_451  X_531  X_727  \\\n",
       "0         NaN    8.24  ...   353.0   13.8  0.000022    NaN    NaN    NaN   \n",
       "1         NaN    8.00  ...   353.0   13.8  0.000005    NaN    NaN    NaN   \n",
       "2         NaN    8.24  ...   353.0   13.8  0.000023    NaN    NaN    NaN   \n",
       "3         NaN    8.00  ...   353.0   13.7  0.000005    NaN    NaN    NaN   \n",
       "4         NaN    8.24  ...   352.0   13.8  0.000024    NaN    NaN    NaN   \n",
       "..        ...     ...  ...     ...    ...       ...    ...    ...    ...   \n",
       "593  0.000003     NaN  ...     NaN    NaN       NaN  416.0    NaN   12.0   \n",
       "594       NaN    8.08  ...   353.0   13.8       NaN    NaN    NaN    NaN   \n",
       "595       NaN    8.08  ...   352.0   13.8       NaN    NaN    NaN    NaN   \n",
       "596  0.000005     NaN  ...     NaN    NaN       NaN  414.0    NaN   24.0   \n",
       "597  0.000003     NaN  ...     NaN    NaN       NaN  418.0    NaN   25.0   \n",
       "\n",
       "     X_1555     X_1530    X_2075  X_511  \n",
       "0       0.0   0.614057  0.000008    NaN  \n",
       "1       0.0   5.535484  0.000003    NaN  \n",
       "2       0.0   5.743548  0.000009    NaN  \n",
       "3       0.0  11.012903  0.000002    NaN  \n",
       "4       0.0   5.322222  0.000008    NaN  \n",
       "..      ...        ...       ...    ...  \n",
       "593     NaN        NaN       NaN    4.7  \n",
       "594     0.0  10.974194       NaN    NaN  \n",
       "595     0.0  10.900000       NaN    NaN  \n",
       "596     NaN        NaN       NaN    4.7  \n",
       "597     NaN        NaN       NaN    4.7  \n",
       "\n",
       "[598 rows x 922 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_importance > 0 인 컬럼만 선택\n",
    "tmp = pd.Series(feat[feat > 0], index=train_x.columns[feat > 0]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2813079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [06:04, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6073395203829987 : [0.14285714 0.68067227 0.68067227] ~ 0.7520202020202019 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6809961582083033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce636c",
   "metadata": {},
   "source": [
    "#### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "661c6ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:31:27, 1817.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0252\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1743\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_932\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_367\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1744\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_368\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_121\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_120\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0118\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_73\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1569\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1716\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_571\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_318\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_248\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_516\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1033\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_62\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_462\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_651\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0034\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_258\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2775 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "perm_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE']) # Feature_importance에서 LINE이 제거됨\n",
    "\n",
    "    perm = PermutationImportance(clf).fit(x_val, y_val) # n_iter = 1\n",
    "    perm_list.append(perm.feature_importances_)\n",
    "    \n",
    "eli5.show_weights(perm, feature_names = x_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3082ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_368</th>\n",
       "      <th>X_367</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_1569</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_380</th>\n",
       "      <th>X_993</th>\n",
       "      <th>...</th>\n",
       "      <th>X_1112</th>\n",
       "      <th>X_1113</th>\n",
       "      <th>X_1114</th>\n",
       "      <th>X_1014</th>\n",
       "      <th>X_2467</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_1179</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_572</th>\n",
       "      <th>X_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.925926</td>\n",
       "      <td>84.111111</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>404.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.981132</td>\n",
       "      <td>84.396226</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>395.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.645161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.018868</td>\n",
       "      <td>84.018868</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>407.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.531250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.962264</td>\n",
       "      <td>84.320755</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>397.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.935484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.111111</td>\n",
       "      <td>85.203704</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.351613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>473.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.612903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.056604</td>\n",
       "      <td>85.037736</td>\n",
       "      <td>3.418868</td>\n",
       "      <td>419.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.132076</td>\n",
       "      <td>84.792453</td>\n",
       "      <td>3.433962</td>\n",
       "      <td>428.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>474.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_368  X_367  X_248   X_73      X_1569  X_258  X_318      X_932  X_380  \\\n",
       "0      NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    0.0   \n",
       "1      NaN    NaN    NaN    NaN  486.593750    NaN    NaN        NaN    0.0   \n",
       "2      NaN    NaN    NaN    NaN  486.645161    NaN    NaN        NaN    0.0   \n",
       "3      NaN    NaN    NaN    NaN  486.531250    NaN    NaN        NaN    0.0   \n",
       "4      NaN    NaN    NaN    NaN  486.935484    NaN    NaN        NaN    0.0   \n",
       "..     ...    ...    ...    ...         ...    ...    ...        ...    ...   \n",
       "593    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.351613    NaN   \n",
       "594    NaN    NaN    NaN    NaN  486.612903    NaN    NaN        NaN    3.0   \n",
       "595    NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    3.0   \n",
       "596    NaN    NaN    NaN  10.22         NaN    NaN    NaN  13.406667    NaN   \n",
       "597    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.380000    NaN   \n",
       "\n",
       "     X_993  ...      X_1112     X_1113    X_1114  X_1014  X_2467   X_12  \\\n",
       "0    102.0  ...  211.925926  84.111111  3.500000   404.0    35.0    NaN   \n",
       "1    103.0  ...  211.981132  84.396226  3.500000   395.0    36.0    NaN   \n",
       "2    103.0  ...  212.018868  84.018868  3.500000   407.0    34.7    NaN   \n",
       "3    104.0  ...  211.962264  84.320755  3.500000   397.0    35.8    NaN   \n",
       "4    109.0  ...  212.111111  85.203704  3.500000   420.0    34.6    NaN   \n",
       "..     ...  ...         ...        ...       ...     ...     ...    ...   \n",
       "593    NaN  ...         NaN        NaN       NaN     NaN     NaN  473.9   \n",
       "594  296.0  ...  212.056604  85.037736  3.418868   419.0    35.6    NaN   \n",
       "595  298.0  ...  212.132076  84.792453  3.433962   428.0    35.6    NaN   \n",
       "596    NaN  ...         NaN        NaN       NaN     NaN     NaN  510.9   \n",
       "597    NaN  ...         NaN        NaN       NaN     NaN     NaN  474.9   \n",
       "\n",
       "     X_1179     X_835  X_572  X_1000  \n",
       "0      20.0       NaN    NaN   411.0  \n",
       "1      21.0       NaN    NaN   414.0  \n",
       "2      22.0       NaN    NaN   417.0  \n",
       "3      22.0       NaN    NaN   421.0  \n",
       "4      22.0       NaN    NaN   441.0  \n",
       "..      ...       ...    ...     ...  \n",
       "593     NaN  9.096774   21.0     NaN  \n",
       "594    23.0       NaN    NaN  1384.0  \n",
       "595    21.0       NaN    NaN  1393.0  \n",
       "596     NaN  9.533333   20.0     NaN  \n",
       "597     NaN  9.033333   21.0     NaN  \n",
       "\n",
       "[598 rows x 262 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_list = np.array(perm_list)\n",
    "perm_mean = np.array([np.mean(perm_list[:, i]) for i in range(len(perm_list[0]))])\n",
    "tmp = pd.Series(perm_mean[(perm_mean > 0)], index=train_x.columns[(perm_mean > 0)]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d077a895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:34, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6336016924252218 : [0.14285714 0.68067227 0.68067227] ~ 0.7886067019400352 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.7106638746496001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f62b244d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# col = [\"X_368\", \"X_367\", \"X_248\", \"X_73\", \"X_1569\", \"X_258\", \"X_318\", \"X_932\", \"X_380\", \"X_993\", \"X_1665\", \"X_1518\", \"X_899\", \"X_121\", \"X_1812\", \"X_1697\", \"X_1330\", \"X_1108\", \"X_1333\", \"X_120\", \"X_968\", \"X_1135\", \"X_1560\", \"X_1155\", \"X_1033\", \"X_556\", \"X_848\", \"X_1433\", \"X_517\", \"X_1346\", \"X_1202\", \"X_423\", \"X_1716\", \"X_718\", \"X_354\", \"X_1089\", \"X_497\", \"X_1473\", \"X_571\", \"X_2862\", \"X_983\", \"X_838\", \"X_374\", \"X_790\", \"X_1406\", \"X_942\", \"X_1378\", \"X_1214\", \"X_1424\", \"X_1172\", \"X_1129\", \"X_1122\", \"X_662\", \"X_1101\", \"X_985\", \"X_967\", \"X_815\", \"X_1058\", \"X_956\", \"X_1054\", \"X_1047\", \"X_1076\", \"X_1292\", \"X_2432\", \"X_346\", \"X_2791\", \"X_1610\", \"X_2794\", \"X_475\", \"X_2780\", \"X_286\", \"X_189\", \"X_256\", \"X_462\", \"X_62\", \"X_1389\", \"X_484\", \"X_388\", \"X_1350\", \"X_1740\", \"X_1471\", \"X_792\", \"X_949\", \"X_1509\", \"X_788\", \"X_1081\", \"X_1082\", \"X_963\", \"X_1373\", \"X_1631\", \"X_915\", \"X_997\", \"X_678\", \"X_1107\", \"X_422\", \"X_1335\", \"X_618\", \"X_1240\", \"X_1231\", \"X_1696\", \"X_995\", \"X_1557\", \"X_437\", \"X_1343\", \"X_1743\", \"X_1176\", \"X_90\", \"X_1647\", \"X_994\", \"X_825\", \"X_1512\", \"X_927\", \"X_1094\", \"X_926\", \"X_257\", \"X_1116\", \"X_397\", \"X_345\", \"X_894\", \"X_1211\", \"X_460\", \"X_1365\", \"X_810\", \"X_536\", \"X_1492\", \"X_2048\", \"X_1640\", \"X_574\", \"X_491\", \"X_660\", \"X_1351\", \"X_339\", \"X_651\", \"X_287\", \"X_616\", \"X_379\", \"X_668\", \"X_1366\", \"X_1532\", \"X_1642\", \"X_1213\", \"X_1551\", \"X_49\", \"X_1260\", \"X_1169\", \"X_1636\", \"X_820\", \"X_1059\", \"X_780\", \"X_2026\", \"X_2050\", \"X_490\", \"X_679\", \"X_661\", \"X_492\", \"X_581\", \"X_1416\", \"X_495\", \"X_2096\", \"X_553\", \"X_552\", \"X_1421\", \"X_506\", \"X_795\", \"X_706\", \"X_1548\", \"X_1048\", \"X_457\", \"X_901\", \"X_918\", \"X_922\", \"X_1530\", \"X_533\", \"X_897\", \"X_2702\", \"X_418\", \"X_417\", \"X_1752\", \"X_613\", \"X_982\", \"X_373\", \"X_1744\", \"X_1353\", \"X_1616\", \"X_698\", \"X_456\", \"X_1149\", \"X_1026\", \"X_45\", \"X_61\", \"X_2797\", \"X_529\", \"X_266\", \"X_712\", \"X_439\", \"X_603\", \"X_1243\", \"X_546\", \"X_2542\", \"X_1638\", \"X_2626\", \"X_2455\", \"X_2704\", \"X_2471\", \"X_2221\", \"X_2347\", \"X_2346\", \"X_2275\", \"X_2122\", \"X_2086\", \"X_2079\", \"X_2019\", \"X_1951\", \"X_1854\", \"X_1850\", \"X_1804\", \"X_1858\", \"X_984\", \"X_1475\", \"X_474\", \"X_667\", \"X_555\", \"X_544\", \"X_543\", \"X_539\", \"X_515\", \"X_502\", \"X_493\", \"X_468\", \"X_714\", \"X_465\", \"X_448\", \"X_436\", \"X_265\", \"X_139\", \"X_126\", \"X_110\", \"X_101\", \"X_1289\", \"X_710\", \"X_769\", \"X_1127\", \"X_1275\", \"X_819\", \"X_827\", \"X_1205\", \"X_855\", \"X_22\", \"X_1163\", \"X_1063\", \"X_791\", \"X_1111\", \"X_1112\", \"X_1113\", \"X_1114\", \"X_1014\", \"X_2467\", \"X_12\", \"X_1179\", \"X_835\", \"X_572\", \"X_1000\"]\n",
    "# train_x = train_x[col]\n",
    "# test_x = test[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92008858",
   "metadata": {},
   "source": [
    "### 결측치 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999f2f0",
   "metadata": {},
   "source": [
    "#### Mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b096ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_368</th>\n",
       "      <th>X_367</th>\n",
       "      <th>X_1744</th>\n",
       "      <th>X_380</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_1338</th>\n",
       "      <th>X_1665</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_1350</th>\n",
       "      <th>X_1343</th>\n",
       "      <th>...</th>\n",
       "      <th>X_242</th>\n",
       "      <th>X_830</th>\n",
       "      <th>X_1100</th>\n",
       "      <th>X_1720</th>\n",
       "      <th>X_1518</th>\n",
       "      <th>X_783</th>\n",
       "      <th>X_792</th>\n",
       "      <th>X_126</th>\n",
       "      <th>X_883</th>\n",
       "      <th>X_1725</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.977171e+09</td>\n",
       "      <td>6.369639e+08</td>\n",
       "      <td>2.640819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.495099e+12</td>\n",
       "      <td>412.548387</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>-4.331044e+20</td>\n",
       "      <td>23.670968</td>\n",
       "      <td>408.096774</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.924307e+19</td>\n",
       "      <td>139.600000</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>12.244898</td>\n",
       "      <td>1.324629e+20</td>\n",
       "      <td>-6.350062e+18</td>\n",
       "      <td>-4.487374e+22</td>\n",
       "      <td>-5.695464e+18</td>\n",
       "      <td>587.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.954278e+09</td>\n",
       "      <td>6.345243e+08</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.489372e+12</td>\n",
       "      <td>414.625000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-4.314408e+20</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>408.218750</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-1.916915e+19</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>7.830040</td>\n",
       "      <td>1.319541e+20</td>\n",
       "      <td>-6.325670e+18</td>\n",
       "      <td>-4.470136e+22</td>\n",
       "      <td>-5.673587e+18</td>\n",
       "      <td>595.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.944520e+09</td>\n",
       "      <td>6.334844e+08</td>\n",
       "      <td>2.545251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.486932e+12</td>\n",
       "      <td>413.967742</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>-4.307317e+20</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>409.290323</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.913765e+19</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.041299</td>\n",
       "      <td>10.958333</td>\n",
       "      <td>1.317372e+20</td>\n",
       "      <td>-6.315273e+18</td>\n",
       "      <td>-4.462789e+22</td>\n",
       "      <td>-5.664262e+18</td>\n",
       "      <td>587.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.928978e+09</td>\n",
       "      <td>6.318282e+08</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.483044e+12</td>\n",
       "      <td>413.875000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>-4.296023e+20</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>408.468750</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-1.908747e+19</td>\n",
       "      <td>126.200000</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>11.803571</td>\n",
       "      <td>1.313918e+20</td>\n",
       "      <td>-6.298714e+18</td>\n",
       "      <td>-4.451086e+22</td>\n",
       "      <td>-5.649410e+18</td>\n",
       "      <td>596.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.864005e+09</td>\n",
       "      <td>6.249042e+08</td>\n",
       "      <td>2.657950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.466792e+12</td>\n",
       "      <td>413.741936</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>-4.248808e+20</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>409.161290</td>\n",
       "      <td>...</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.887769e+19</td>\n",
       "      <td>152.100000</td>\n",
       "      <td>0.036676</td>\n",
       "      <td>12.020408</td>\n",
       "      <td>1.299477e+20</td>\n",
       "      <td>-6.229485e+18</td>\n",
       "      <td>-4.402163e+22</td>\n",
       "      <td>-5.587319e+18</td>\n",
       "      <td>587.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>3.469384e+01</td>\n",
       "      <td>3.529478e+01</td>\n",
       "      <td>1.131113</td>\n",
       "      <td>11.229859</td>\n",
       "      <td>5.290299e+01</td>\n",
       "      <td>465.321150</td>\n",
       "      <td>7.246126</td>\n",
       "      <td>1.009000e+01</td>\n",
       "      <td>24.821861</td>\n",
       "      <td>531.581910</td>\n",
       "      <td>...</td>\n",
       "      <td>35.350951</td>\n",
       "      <td>6.900000e+00</td>\n",
       "      <td>174.548067</td>\n",
       "      <td>0.043468</td>\n",
       "      <td>12.417025</td>\n",
       "      <td>1.309346e+01</td>\n",
       "      <td>4.121935e+02</td>\n",
       "      <td>6.608000e+03</td>\n",
       "      <td>7.628571e+00</td>\n",
       "      <td>585.331081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>3.466393e+01</td>\n",
       "      <td>3.526934e+01</td>\n",
       "      <td>0.717637</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.242664e+01</td>\n",
       "      <td>409.129032</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>3.591270e+18</td>\n",
       "      <td>25.280645</td>\n",
       "      <td>402.838710</td>\n",
       "      <td>...</td>\n",
       "      <td>35.700000</td>\n",
       "      <td>1.592768e+17</td>\n",
       "      <td>185.100000</td>\n",
       "      <td>0.040157</td>\n",
       "      <td>12.865979</td>\n",
       "      <td>-1.101059e+18</td>\n",
       "      <td>5.315058e+16</td>\n",
       "      <td>3.820543e+20</td>\n",
       "      <td>4.734567e+16</td>\n",
       "      <td>594.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>3.466361e+01</td>\n",
       "      <td>3.526909e+01</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.237216e+01</td>\n",
       "      <td>409.580645</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>3.564793e+18</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>403.548387</td>\n",
       "      <td>...</td>\n",
       "      <td>35.700000</td>\n",
       "      <td>1.581025e+17</td>\n",
       "      <td>187.600000</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>13.171271</td>\n",
       "      <td>-1.092941e+18</td>\n",
       "      <td>5.275871e+16</td>\n",
       "      <td>3.792375e+20</td>\n",
       "      <td>4.699659e+16</td>\n",
       "      <td>594.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>3.469384e+01</td>\n",
       "      <td>3.529478e+01</td>\n",
       "      <td>1.131111</td>\n",
       "      <td>11.229841</td>\n",
       "      <td>5.290310e+01</td>\n",
       "      <td>465.320771</td>\n",
       "      <td>7.246163</td>\n",
       "      <td>1.022000e+01</td>\n",
       "      <td>24.821861</td>\n",
       "      <td>531.581234</td>\n",
       "      <td>...</td>\n",
       "      <td>35.350960</td>\n",
       "      <td>6.800000e+00</td>\n",
       "      <td>174.547859</td>\n",
       "      <td>0.043468</td>\n",
       "      <td>12.417024</td>\n",
       "      <td>1.302564e+01</td>\n",
       "      <td>4.125667e+02</td>\n",
       "      <td>1.582400e+04</td>\n",
       "      <td>7.410000e+00</td>\n",
       "      <td>585.331215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>3.469384e+01</td>\n",
       "      <td>3.529478e+01</td>\n",
       "      <td>1.131113</td>\n",
       "      <td>11.229859</td>\n",
       "      <td>5.290299e+01</td>\n",
       "      <td>465.321116</td>\n",
       "      <td>7.246129</td>\n",
       "      <td>1.009000e+01</td>\n",
       "      <td>24.821861</td>\n",
       "      <td>531.581903</td>\n",
       "      <td>...</td>\n",
       "      <td>35.350951</td>\n",
       "      <td>6.800000e+00</td>\n",
       "      <td>174.548059</td>\n",
       "      <td>0.043468</td>\n",
       "      <td>12.417026</td>\n",
       "      <td>1.345070e+01</td>\n",
       "      <td>4.120667e+02</td>\n",
       "      <td>6.626000e+03</td>\n",
       "      <td>7.738776e+00</td>\n",
       "      <td>585.331081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X_368         X_367    X_1744      X_380         X_248  \\\n",
       "0   -5.977171e+09  6.369639e+08  2.640819   0.000000 -1.495099e+12   \n",
       "1   -5.954278e+09  6.345243e+08  0.927656   0.000000 -1.489372e+12   \n",
       "2   -5.944520e+09  6.334844e+08  2.545251   0.000000 -1.486932e+12   \n",
       "3   -5.928978e+09  6.318282e+08  0.960523   0.000000 -1.483044e+12   \n",
       "4   -5.864005e+09  6.249042e+08  2.657950   0.000000 -1.466792e+12   \n",
       "..            ...           ...       ...        ...           ...   \n",
       "593  3.469384e+01  3.529478e+01  1.131113  11.229859  5.290299e+01   \n",
       "594  3.466393e+01  3.526934e+01  0.717637   3.000000  6.242664e+01   \n",
       "595  3.466361e+01  3.526909e+01  0.666314   3.000000  6.237216e+01   \n",
       "596  3.469384e+01  3.529478e+01  1.131111  11.229841  5.290310e+01   \n",
       "597  3.469384e+01  3.529478e+01  1.131113  11.229859  5.290299e+01   \n",
       "\n",
       "         X_1338     X_1665          X_73     X_1350      X_1343  ...  \\\n",
       "0    412.548387  12.200000 -4.331044e+20  23.670968  408.096774  ...   \n",
       "1    414.625000  12.000000 -4.314408e+20  23.700000  408.218750  ...   \n",
       "2    413.967742  11.900000 -4.307317e+20  23.800000  409.290323  ...   \n",
       "3    413.875000  12.500000 -4.296023e+20  23.900000  408.468750  ...   \n",
       "4    413.741936  11.800000 -4.248808e+20  24.200000  409.161290  ...   \n",
       "..          ...        ...           ...        ...         ...  ...   \n",
       "593  465.321150   7.246126  1.009000e+01  24.821861  531.581910  ...   \n",
       "594  409.129032  14.400000  3.591270e+18  25.280645  402.838710  ...   \n",
       "595  409.580645  13.700000  3.564793e+18  25.290323  403.548387  ...   \n",
       "596  465.320771   7.246163  1.022000e+01  24.821861  531.581234  ...   \n",
       "597  465.321116   7.246129  1.009000e+01  24.821861  531.581903  ...   \n",
       "\n",
       "         X_242         X_830      X_1100    X_1720     X_1518         X_783  \\\n",
       "0    35.000000 -1.924307e+19  139.600000  0.039447  12.244898  1.324629e+20   \n",
       "1    36.000000 -1.916915e+19  145.500000  0.049628   7.830040  1.319541e+20   \n",
       "2    35.000000 -1.913765e+19  128.000000  0.041299  10.958333  1.317372e+20   \n",
       "3    36.000000 -1.908747e+19  126.200000  0.049778  11.803571  1.313918e+20   \n",
       "4    35.000000 -1.887769e+19  152.100000  0.036676  12.020408  1.299477e+20   \n",
       "..         ...           ...         ...       ...        ...           ...   \n",
       "593  35.350951  6.900000e+00  174.548067  0.043468  12.417025  1.309346e+01   \n",
       "594  35.700000  1.592768e+17  185.100000  0.040157  12.865979 -1.101059e+18   \n",
       "595  35.700000  1.581025e+17  187.600000  0.041395  13.171271 -1.092941e+18   \n",
       "596  35.350960  6.800000e+00  174.547859  0.043468  12.417024  1.302564e+01   \n",
       "597  35.350951  6.800000e+00  174.548059  0.043468  12.417026  1.345070e+01   \n",
       "\n",
       "            X_792         X_126         X_883      X_1725  \n",
       "0   -6.350062e+18 -4.487374e+22 -5.695464e+18  587.100000  \n",
       "1   -6.325670e+18 -4.470136e+22 -5.673587e+18  595.700000  \n",
       "2   -6.315273e+18 -4.462789e+22 -5.664262e+18  587.500000  \n",
       "3   -6.298714e+18 -4.451086e+22 -5.649410e+18  596.100000  \n",
       "4   -6.229485e+18 -4.402163e+22 -5.587319e+18  587.200000  \n",
       "..            ...           ...           ...         ...  \n",
       "593  4.121935e+02  6.608000e+03  7.628571e+00  585.331081  \n",
       "594  5.315058e+16  3.820543e+20  4.734567e+16  594.600000  \n",
       "595  5.275871e+16  3.792375e+20  4.699659e+16  594.500000  \n",
       "596  4.125667e+02  1.582400e+04  7.410000e+00  585.331215  \n",
       "597  4.120667e+02  6.626000e+03  7.738776e+00  585.331081  \n",
       "\n",
       "[598 rows x 99 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mice = IterativeImputer()\n",
    "train_x_mice = mice.fit_transform(train_x)\n",
    "train_x_mice = pd.DataFrame(train_x_mice, columns=train_x.columns)\n",
    "test_mice = pd.DataFrame(mice.transform(test), columns=test.columns)\n",
    "\n",
    "# 메모리 초과를 막기위해 제거\n",
    "import gc\n",
    "del mice\n",
    "gc.collect()\n",
    "\n",
    "train_x_mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e3fa13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:39, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5712708877801537 : [0.14285714 0.68067227 0.68067227] ~ 0.7764196587725999 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6755783532453521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x_mice, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x_mice.loc[train_index], train_x_mice.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad362d",
   "metadata": {},
   "source": [
    "#### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10d54956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_fill0 = train_x.fillna(0)\n",
    "test_fill0 = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df292fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:39, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742573835345475 : [0.15  0.675 0.675] ~ 0.8324393358876118 : [0.15  0.675 0.675]\n",
      "mean : 0.7281825945685947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x_fill0, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x_fill0.loc[train_index], train_x_fill0.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f009faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x_fill0\n",
    "test = test_fill0\n",
    "# train_x = train_x_mice\n",
    "# test = test_mice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c296",
   "metadata": {},
   "source": [
    "### Data Scaling (random, SMOTE ENN, SMOTE Tomek, ADASYN, Borderline SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d8790e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomoversampler(train_x_df, train_y_df):\n",
    "    x_ros, y_ros = RandomOverSampler().fit_resample(train_x_df, train_y_df)\n",
    "    return x_ros, y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "720865d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_Tomek(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTETomek().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3fd930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_ENN(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTEENN().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bed1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADASYN_(train_x_df, train_y_df):\n",
    "    x_adasyn, y_adasyn = ADASYN(sampling_strategy='minority').fit_resample(train_x_df, train_y_df)\n",
    "    return x_adasyn, y_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cecbf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Borderline_SMOTE(train_x_df, train_y_df):\n",
    "    x_b_smote, y_b_smote = BorderlineSMOTE().fit_resample(train_x_df, train_y_df)\n",
    "    return x_b_smote, y_b_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6e18",
   "metadata": {},
   "source": [
    "#### RandomOverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cb776b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:23, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581973581973582 : [0.14285714 0.68067227 0.68067227] ~ 0.8295608301800254 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.70366517590556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Randomoversampler(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a0f11",
   "metadata": {},
   "source": [
    "#### SMOTE_ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb7cd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:16, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45041014168530946 : [0.15       0.68333333 0.68333333] ~ 0.6354913014487482 : [0.15       0.68333333 0.68333333]\n",
      "mean : 0.5570092475602809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_ENN(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac5a5",
   "metadata": {},
   "source": [
    "#### SMOTE_Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d857227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:14, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5806049768437126 : [0.14285714 0.68067227 0.68067227] ~ 0.7638920876196326 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6812701859714365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_Tomek(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b428a",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c002771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:16, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5848125873276229 : [0.14285714 0.68067227 0.68067227] ~ 0.8643483709273182 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6946860653244584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d612d",
   "metadata": {},
   "source": [
    "#### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9122ab3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:15, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.589404625629285 : [0.14285714 0.68067227 0.68067227] ~ 0.8161220043572984 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.7083089438394669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Borderline_SMOTE(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} : {class_rate[f1_list.index(min(f1_list))]} ~ {max(f1_list)} : {class_rate[f1_list.index(min(f1_list))]}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09010b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c2475ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.to_csv('train_x_pp.csv', index=False)\n",
    "# train_y.to_csv('train_y_pp.csv', index=False)\n",
    "# test.to_csv('test_pp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "badcdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_objective(trial):\n",
    "\n",
    "    params = {\n",
    "            'iterations':trial.suggest_int(\"iterations\", 500, 3000),\n",
    "            'objective':trial.suggest_categorical('objective',['MultiClass']),\n",
    "            #'bootstrap_type':trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "            'od_wait':trial.suggest_int('od_wait', 500, 1000),\n",
    "            'learning_rate' : trial.suggest_uniform('learning_rate',0.01,1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
    "            'random_strength': trial.suggest_uniform('random_strength',20,50),\n",
    "            'depth': trial.suggest_int('depth',1,15),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,20),\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
    "            'verbose': False,\n",
    "            \"eval_metric\":'TotalF1',\n",
    "            #\"cat_features\" : ['PRODUCT_CODE', 'LINE'],\n",
    "            \"one_hot_max_size\": trial.suggest_int(\"one_hot_max_size\",1,5),\n",
    "            'task_type' : 'GPU',\n",
    "            #'thread_count': 5,\n",
    "        }\n",
    "\n",
    "#     if params['bootstrap_type'] == 'Bayesian':\n",
    "#         params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "#     elif params['bootstrap_type'] == 'Bernoulli':\n",
    "#         params['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "    \n",
    "    rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "    clf = catboost.CatBoostClassifier(**params)\n",
    "\n",
    "    f1_list = []\n",
    "    for fold, (train_index, val_index) in enumerate(rskfold.split(train_x, train_y)):\n",
    "        x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "        x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "        \n",
    "        clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "        f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "        print(1)\n",
    "    \n",
    "    return np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d785ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-17 01:19:40,193]\u001b[0m A new study created in memory with name: no-name-333da0bb-b053-46ac-87ff-d36dc825c2c1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010881423950195312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84391f56ffcc47559e016054a91e3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(cb_objective, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69fdc5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1337,\n",
       " 'objective': 'MultiClass',\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'od_wait': 552,\n",
       " 'learning_rate': 0.6128454724915484,\n",
       " 'reg_lambda': 77.08090755141544,\n",
       " 'random_strength': 43.1413895840195,\n",
       " 'depth': 3,\n",
       " 'min_data_in_leaf': 20,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'one_hot_max_size': 1,\n",
       " 'bagging_temperature': 0.06040383536784377}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(study.best_trial)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f303d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = catboost.CatBoostClassifier(**study.best_params, verbose=0).fit(train_x, train_y)\n",
    "pred = clf.predict(test)\n",
    "subm['Y_Class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71115eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = catboost.CatBoostClassifier(task_type='GPU', verbose=0).fit(train_x, train_y)\n",
    "pred = clf.predict(test)\n",
    "subm['Y_Class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cafef374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    264\n",
       "0     39\n",
       "2      7\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.Y_Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "680aa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('./submission_36_feat_del.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff12055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 / 1, 2 랑 0, 1 / 2로 나누어서? 모델을 두 가지 만들면 될 듯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
