{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa7efeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Permutation Importance & Visualization\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Scikit - learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Data Scaling\n",
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Model & AutoML\n",
    "import catboost\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe1223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature importance 무한히 돌리기\n",
    "### threshold\n",
    "\n",
    "# corr 그래프 등 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee207fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2bb4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "subm = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a392cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRODUCT_ID  Y_Class  Y_Quality        TIMESTAMP     LINE PRODUCT_CODE  X_1  \\\n",
       "0  TRAIN_000        1   0.533433  2022-06-13 5:14  T050304         A_31  NaN   \n",
       "1  TRAIN_001        2   0.541819  2022-06-13 5:22  T050307         A_31  NaN   \n",
       "2  TRAIN_002        1   0.531267  2022-06-13 5:30  T050304         A_31  NaN   \n",
       "3  TRAIN_003        2   0.537325  2022-06-13 5:39  T050307         A_31  NaN   \n",
       "4  TRAIN_004        1   0.531590  2022-06-13 5:47  T050304         A_31  NaN   \n",
       "\n",
       "   X_2  X_3  X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
       "0  NaN  NaN  NaN  ...   39.34   40.89   32.56   34.09   77.77     NaN     NaN   \n",
       "1  NaN  NaN  NaN  ...   38.89   42.82   43.92   35.34   72.55     NaN     NaN   \n",
       "2  NaN  NaN  NaN  ...   39.19   36.65   42.47   36.53   78.35     NaN     NaN   \n",
       "3  NaN  NaN  NaN  ...   37.74   39.17   52.17   30.58   71.78     NaN     NaN   \n",
       "4  NaN  NaN  NaN  ...   38.70   41.89   46.93   33.09   76.97     NaN     NaN   \n",
       "\n",
       "   X_2873  X_2874  X_2875  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 2881 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['PRODUCT_CODE'] = train['PRODUCT_CODE'].astype('category')\n",
    "train['LINE'] = train['LINE'].astype('category')\n",
    "\n",
    "test['PRODUCT_CODE'] = test['PRODUCT_CODE'].astype('category')\n",
    "test['LINE'] = test['LINE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a8bfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 열의 유일한 값이 nan이거나 모두 같은 값인 경우 해당 열을 제외\n",
    "def remove_col(train_df, test_df):\n",
    "    for x in train_df.columns[6:]:\n",
    "        if train_df[x].nunique()==0 or (train_df[x].nunique()==1 and len(train_df[x].unique())==1): # nan 이거나 모두 같은 값인 경우\n",
    "            train_df.drop(columns=[x], inplace=True)\n",
    "            test_df.drop(columns=[x], inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30fd903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_col(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b596197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Quality'], inplace=True)\n",
    "\n",
    "test = test[train.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a62fbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train.drop(columns=['Y_Class']), train['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6689b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2862</th>\n",
       "      <th>X_2863</th>\n",
       "      <th>X_2864</th>\n",
       "      <th>X_2865</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>368.296296</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>185.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.735849</td>\n",
       "      <td>353.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.5</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.320755</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.8</td>\n",
       "      <td>384.0</td>\n",
       "      <td>369.188679</td>\n",
       "      <td>353.0</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>182.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.351852</td>\n",
       "      <td>352.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LINE PRODUCT_CODE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  ...  X_2862  \\\n",
       "0  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   189.0   \n",
       "1  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   185.6   \n",
       "2  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.5   \n",
       "3  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.8   \n",
       "4  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   182.6   \n",
       "\n",
       "   X_2863      X_2864  X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \n",
       "0   383.0  368.296296   353.0   39.34   40.89   32.56   34.09   77.77     NaN  \n",
       "1   383.0  367.735849   353.0   38.89   42.82   43.92   35.34   72.55     NaN  \n",
       "2   383.0  367.320755   353.0   39.19   36.65   42.47   36.53   78.35     NaN  \n",
       "3   384.0  369.188679   353.0   37.74   39.17   52.17   30.58   71.78     NaN  \n",
       "4   383.0  367.351852   352.0   38.70   41.89   46.93   33.09   76.97     NaN  \n",
       "\n",
       "[5 rows x 2795 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2555d",
   "metadata": {},
   "source": [
    "### catboost cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a908d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9c4025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [06:01, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5811609030761885 : [0.14285714 0.68067227 0.68067227] ~ 0.7829945233454004 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6609634746016518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6de3cb",
   "metadata": {},
   "source": [
    "### Feature & Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cca278",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c06f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "clf.fit(train_x, train_y, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "\n",
    "feat = clf.feature_importances_\n",
    "feature_imp = pd.Series(feat, index=train_x.columns).sort_values(ascending=False)[:20].sort_values()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 15)\n",
    "plt.barh(feature_imp.index, feature_imp)\n",
    "plt.title('Feature_importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9d6a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_121</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_790</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_256</th>\n",
       "      <th>X_899</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2449</th>\n",
       "      <th>X_1886</th>\n",
       "      <th>X_113</th>\n",
       "      <th>X_1930</th>\n",
       "      <th>X_1922</th>\n",
       "      <th>X_752</th>\n",
       "      <th>X_2040</th>\n",
       "      <th>X_594</th>\n",
       "      <th>X_1097</th>\n",
       "      <th>X_564</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>205.004412</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>204.994286</td>\n",
       "      <td>0.05461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036011</td>\n",
       "      <td>0.453569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>204.995588</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>204.998551</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>204.994030</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>13.351613</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>205.005797</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>204.997101</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>13.406667</td>\n",
       "      <td>10.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>739.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>13.380000</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>739.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.163265</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 962 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_932   X_73  X_318  X_121  X_258  X_790  X_248     X_835  X_256  \\\n",
       "0          NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "1          NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "2          NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "3          NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "4          NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "..         ...    ...    ...    ...    ...    ...    ...       ...    ...   \n",
       "593  13.351613  10.09    NaN   34.1    NaN  737.0    NaN  9.096774    NaN   \n",
       "594        NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "595        NaN    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN   \n",
       "596  13.406667  10.22    NaN   33.7    NaN  739.0    NaN  9.533333    NaN   \n",
       "597  13.380000  10.09    NaN   34.1    NaN  739.0    NaN  9.033333    NaN   \n",
       "\n",
       "        X_899  ...      X_2449   X_1886  X_113    X_1930    X_1922  X_752  \\\n",
       "0         NaN  ...  205.004412  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "1         NaN  ...  204.994286  0.05461    NaN  0.036011  0.453569    NaN   \n",
       "2         NaN  ...  204.995588  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "3         NaN  ...  204.998551  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "4         NaN  ...  204.994030  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "..        ...  ...         ...      ...    ...       ...       ...    ...   \n",
       "593  7.061224  ...         NaN      NaN    NaN       NaN       NaN    4.7   \n",
       "594       NaN  ...  205.005797  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "595       NaN  ...  204.997101  0.00000    NaN  0.000000  0.000000    NaN   \n",
       "596  6.720000  ...         NaN      NaN   0.19       NaN       NaN    4.7   \n",
       "597  7.163265  ...         NaN      NaN    NaN       NaN       NaN    4.7   \n",
       "\n",
       "       X_2040  X_594  X_1097  X_564  \n",
       "0    0.000022    NaN    39.0    NaN  \n",
       "1    0.000004    NaN    34.0    NaN  \n",
       "2    0.000021    NaN    35.0    NaN  \n",
       "3    0.000003    NaN    38.0    NaN  \n",
       "4    0.000020    NaN    36.0    NaN  \n",
       "..        ...    ...     ...    ...  \n",
       "593       NaN    0.1     NaN   15.0  \n",
       "594       NaN    NaN    35.0    NaN  \n",
       "595       NaN    NaN    37.0    NaN  \n",
       "596       NaN    0.4     NaN   15.0  \n",
       "597       NaN    0.3     NaN   14.0  \n",
       "\n",
       "[598 rows x 962 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_importance > 0 인 컬럼만 선택\n",
    "tmp = pd.Series(feat[feat > 0], index=train_x.columns[feat > 0]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44979b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col cnt : 781\n",
      "col cnt : 708\n",
      "col cnt : 666\n",
      "col cnt : 631\n",
      "col cnt : 612\n",
      "col cnt : 591\n",
      "col cnt : 574\n",
      "col cnt : 565\n",
      "col cnt : 552\n",
      "col cnt : 547\n",
      "col cnt : 541\n",
      "col cnt : 533\n",
      "col cnt : 529\n",
      "col cnt : 520\n",
      "col cnt : 515\n",
      "col cnt : 513\n",
      "col cnt : 508\n",
      "col cnt : 503\n",
      "col cnt : 498\n",
      "col cnt : 493\n",
      "col cnt : 490\n",
      "col cnt : 486\n",
      "col cnt : 483\n",
      "col cnt : 481\n",
      "col cnt : 478\n",
      "col cnt : 474\n",
      "col cnt : 473\n",
      "col cnt : 470\n",
      "col cnt : 466\n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "    clf.fit(train_x, train_y, early_stopping_rounds=100)\n",
    "    \n",
    "    feat = clf.feature_importances_\n",
    "    tmp = pd.Series(feat[feat > 0], index=train_x.columns[feat > 0]).sort_values(ascending=False)[:]\n",
    "    if len(tmp) == len(train_x.columns):\n",
    "        break\n",
    "    print('col cnt :', len(tmp))\n",
    "    train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1da4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:56, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195245919596889 ~ 0.7974871547848427\n",
      "mean : 0.6965416058252865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6637f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ceba74ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753985544835218\n",
      "0.688506923129391\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for proba in clf.predict_proba(x_val):\n",
    "    if list(proba).index(max(proba)) == 1 and max(proba) < 0.8:\n",
    "        if proba[0] > proba[2]: \n",
    "            pred.append(0)\n",
    "        elif proba[0] < proba[2]:\n",
    "            pred.append(2)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    else:\n",
    "        pred.append(list(proba).index(max(proba)))\n",
    "        \n",
    "print(f1_score(pred, y_val, average='macro'))\n",
    "\n",
    "print(f1_score(clf.predict(x_val), y_val, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cefc4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:46, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947919244008629 ~ 0.7885494502156613\n",
      "mean : 0.7146152143180311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    pred = []\n",
    "    for proba in clf.predict_proba(x_val):\n",
    "        if list(proba).index(max(proba)) == 1 and max(proba) < threshold:\n",
    "            if proba[0] > proba[2]: \n",
    "                pred.append(0)\n",
    "            elif proba[0] < proba[2]:\n",
    "                pred.append(2)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "        else:\n",
    "            pred.append(list(proba).index(max(proba)))\n",
    "            \n",
    "    f1_list.append(f1_score(pred, y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a1b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b62c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3f59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04955da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b31d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fce636c",
   "metadata": {},
   "source": [
    "#### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fa902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance는 영향력을 확인하는 것이다. column이 매우 많은 상황에서 score에 대한 영향력을 확인하는 것도 좋지만,\n",
    "# 결측치가 많고, test set에서 해당 columns이 어떤 상황일지 모르는 데 이 과정을 통해 column을 제거하는 것은 부정적인 영향을 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4399718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = [\"X_368\", \"X_367\", \"X_248\", \"X_73\", \"X_1569\", \"X_258\", \"X_318\", \"X_932\", \"X_380\", \"X_993\", \"X_1665\", \"X_1518\", \"X_899\", \"X_121\", \"X_1812\", \"X_1697\", \"X_1330\", \"X_1108\", \"X_1333\", \"X_120\", \"X_968\", \"X_1135\", \"X_1560\", \"X_1155\", \"X_1033\", \"X_556\", \"X_848\", \"X_1433\", \"X_517\", \"X_1346\", \"X_1202\", \"X_423\", \"X_1716\", \"X_718\", \"X_354\", \"X_1089\", \"X_497\", \"X_1473\", \"X_571\", \"X_2862\", \"X_983\", \"X_838\", \"X_374\", \"X_790\", \"X_1406\", \"X_942\", \"X_1378\", \"X_1214\", \"X_1424\", \"X_1172\", \"X_1129\", \"X_1122\", \"X_662\", \"X_1101\", \"X_985\", \"X_967\", \"X_815\", \"X_1058\", \"X_956\", \"X_1054\", \"X_1047\", \"X_1076\", \"X_1292\", \"X_2432\", \"X_346\", \"X_2791\", \"X_1610\", \"X_2794\", \"X_475\", \"X_2780\", \"X_286\", \"X_189\", \"X_256\", \"X_462\", \"X_62\", \"X_1389\", \"X_484\", \"X_388\", \"X_1350\", \"X_1740\", \"X_1471\", \"X_792\", \"X_949\", \"X_1509\", \"X_788\", \"X_1081\", \"X_1082\", \"X_963\", \"X_1373\", \"X_1631\", \"X_915\", \"X_997\", \"X_678\", \"X_1107\", \"X_422\", \"X_1335\", \"X_618\", \"X_1240\", \"X_1231\", \"X_1696\", \"X_995\", \"X_1557\", \"X_437\", \"X_1343\", \"X_1743\", \"X_1176\", \"X_90\", \"X_1647\", \"X_994\", \"X_825\", \"X_1512\", \"X_927\", \"X_1094\", \"X_926\", \"X_257\", \"X_1116\", \"X_397\", \"X_345\", \"X_894\", \"X_1211\", \"X_460\", \"X_1365\", \"X_810\", \"X_536\", \"X_1492\", \"X_2048\", \"X_1640\", \"X_574\", \"X_491\", \"X_660\", \"X_1351\", \"X_339\", \"X_651\", \"X_287\", \"X_616\", \"X_379\", \"X_668\", \"X_1366\", \"X_1532\", \"X_1642\", \"X_1213\", \"X_1551\", \"X_49\", \"X_1260\", \"X_1169\", \"X_1636\", \"X_820\", \"X_1059\", \"X_780\", \"X_2026\", \"X_2050\", \"X_490\", \"X_679\", \"X_661\", \"X_492\", \"X_581\", \"X_1416\", \"X_495\", \"X_2096\", \"X_553\", \"X_552\", \"X_1421\", \"X_506\", \"X_795\", \"X_706\", \"X_1548\", \"X_1048\", \"X_457\", \"X_901\", \"X_918\", \"X_922\", \"X_1530\", \"X_533\", \"X_897\", \"X_2702\", \"X_418\", \"X_417\", \"X_1752\", \"X_613\", \"X_982\", \"X_373\", \"X_1744\", \"X_1353\", \"X_1616\", \"X_698\", \"X_456\", \"X_1149\", \"X_1026\", \"X_45\", \"X_61\", \"X_2797\", \"X_529\", \"X_266\", \"X_712\", \"X_439\", \"X_603\", \"X_1243\", \"X_546\", \"X_2542\", \"X_1638\", \"X_2626\", \"X_2455\", \"X_2704\", \"X_2471\", \"X_2221\", \"X_2347\", \"X_2346\", \"X_2275\", \"X_2122\", \"X_2086\", \"X_2079\", \"X_2019\", \"X_1951\", \"X_1854\", \"X_1850\", \"X_1804\", \"X_1858\", \"X_984\", \"X_1475\", \"X_474\", \"X_667\", \"X_555\", \"X_544\", \"X_543\", \"X_539\", \"X_515\", \"X_502\", \"X_493\", \"X_468\", \"X_714\", \"X_465\", \"X_448\", \"X_436\", \"X_265\", \"X_139\", \"X_126\", \"X_110\", \"X_101\", \"X_1289\", \"X_710\", \"X_769\", \"X_1127\", \"X_1275\", \"X_819\", \"X_827\", \"X_1205\", \"X_855\", \"X_22\", \"X_1163\", \"X_1063\", \"X_791\", \"X_1111\", \"X_1112\", \"X_1113\", \"X_1114\", \"X_1014\", \"X_2467\", \"X_12\", \"X_1179\", \"X_835\", \"X_572\", \"X_1000\"]\n",
    "# train_x = train_x[col]\n",
    "# test_x = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "661c6ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:31:27, 1817.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0252\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1743\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_932\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_367\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1744\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_368\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_121\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_120\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0118\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_73\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1569\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1716\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_571\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_318\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_248\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_516\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1033\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_62\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_462\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_651\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0034\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_258\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2775 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "perm_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE']) # Feature_importance에서 LINE이 제거됨\n",
    "\n",
    "    perm = PermutationImportance(clf).fit(x_val, y_val) # n_iter = 1\n",
    "    perm_list.append(perm.feature_importances_)\n",
    "    \n",
    "eli5.show_weights(perm, feature_names = x_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3082ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_368</th>\n",
       "      <th>X_367</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_1569</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_380</th>\n",
       "      <th>X_993</th>\n",
       "      <th>...</th>\n",
       "      <th>X_1112</th>\n",
       "      <th>X_1113</th>\n",
       "      <th>X_1114</th>\n",
       "      <th>X_1014</th>\n",
       "      <th>X_2467</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_1179</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_572</th>\n",
       "      <th>X_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.925926</td>\n",
       "      <td>84.111111</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>404.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.981132</td>\n",
       "      <td>84.396226</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>395.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.645161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.018868</td>\n",
       "      <td>84.018868</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>407.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.531250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.962264</td>\n",
       "      <td>84.320755</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>397.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.935484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.111111</td>\n",
       "      <td>85.203704</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.351613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>473.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.612903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.056604</td>\n",
       "      <td>85.037736</td>\n",
       "      <td>3.418868</td>\n",
       "      <td>419.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.132076</td>\n",
       "      <td>84.792453</td>\n",
       "      <td>3.433962</td>\n",
       "      <td>428.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>474.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_368  X_367  X_248   X_73      X_1569  X_258  X_318      X_932  X_380  \\\n",
       "0      NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    0.0   \n",
       "1      NaN    NaN    NaN    NaN  486.593750    NaN    NaN        NaN    0.0   \n",
       "2      NaN    NaN    NaN    NaN  486.645161    NaN    NaN        NaN    0.0   \n",
       "3      NaN    NaN    NaN    NaN  486.531250    NaN    NaN        NaN    0.0   \n",
       "4      NaN    NaN    NaN    NaN  486.935484    NaN    NaN        NaN    0.0   \n",
       "..     ...    ...    ...    ...         ...    ...    ...        ...    ...   \n",
       "593    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.351613    NaN   \n",
       "594    NaN    NaN    NaN    NaN  486.612903    NaN    NaN        NaN    3.0   \n",
       "595    NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    3.0   \n",
       "596    NaN    NaN    NaN  10.22         NaN    NaN    NaN  13.406667    NaN   \n",
       "597    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.380000    NaN   \n",
       "\n",
       "     X_993  ...      X_1112     X_1113    X_1114  X_1014  X_2467   X_12  \\\n",
       "0    102.0  ...  211.925926  84.111111  3.500000   404.0    35.0    NaN   \n",
       "1    103.0  ...  211.981132  84.396226  3.500000   395.0    36.0    NaN   \n",
       "2    103.0  ...  212.018868  84.018868  3.500000   407.0    34.7    NaN   \n",
       "3    104.0  ...  211.962264  84.320755  3.500000   397.0    35.8    NaN   \n",
       "4    109.0  ...  212.111111  85.203704  3.500000   420.0    34.6    NaN   \n",
       "..     ...  ...         ...        ...       ...     ...     ...    ...   \n",
       "593    NaN  ...         NaN        NaN       NaN     NaN     NaN  473.9   \n",
       "594  296.0  ...  212.056604  85.037736  3.418868   419.0    35.6    NaN   \n",
       "595  298.0  ...  212.132076  84.792453  3.433962   428.0    35.6    NaN   \n",
       "596    NaN  ...         NaN        NaN       NaN     NaN     NaN  510.9   \n",
       "597    NaN  ...         NaN        NaN       NaN     NaN     NaN  474.9   \n",
       "\n",
       "     X_1179     X_835  X_572  X_1000  \n",
       "0      20.0       NaN    NaN   411.0  \n",
       "1      21.0       NaN    NaN   414.0  \n",
       "2      22.0       NaN    NaN   417.0  \n",
       "3      22.0       NaN    NaN   421.0  \n",
       "4      22.0       NaN    NaN   441.0  \n",
       "..      ...       ...    ...     ...  \n",
       "593     NaN  9.096774   21.0     NaN  \n",
       "594    23.0       NaN    NaN  1384.0  \n",
       "595    21.0       NaN    NaN  1393.0  \n",
       "596     NaN  9.533333   20.0     NaN  \n",
       "597     NaN  9.033333   21.0     NaN  \n",
       "\n",
       "[598 rows x 262 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_list = np.array(perm_list)\n",
    "perm_mean = np.array([np.mean(perm_list[:, i]) for i in range(len(perm_list[0]))])\n",
    "tmp = pd.Series(perm_mean[(perm_mean > 0)], index=train_x.columns[(perm_mean > 0)]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d077a895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:27, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639344766119614 : [0.15       0.68333333 0.68333333] ~ 0.8053274949826674 : [0.15       0.68333333 0.68333333]\n",
      "mean : 0.7111273645948281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892d185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92008858",
   "metadata": {},
   "source": [
    "### 결측치 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad362d",
   "metadata": {},
   "source": [
    "#### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10d54956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df292fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:57, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5946844319775596 ~ 0.7632555715889048\n",
      "mean : 0.6956812485682076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c296",
   "metadata": {},
   "source": [
    "### Data Scaling (random, SMOTE ENN, SMOTE Tomek, ADASYN, Borderline SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d8790e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomoversampler(train_x_df, train_y_df):\n",
    "    x_ros, y_ros = RandomOverSampler().fit_resample(train_x_df, train_y_df)\n",
    "    return x_ros, y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720865d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_Tomek(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTETomek().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3fd930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_ENN(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTEENN().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bed1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADASYN_(train_x_df, train_y_df):\n",
    "    x_adasyn, y_adasyn = ADASYN(sampling_strategy='minority').fit_resample(train_x_df, train_y_df)\n",
    "    return x_adasyn, y_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cecbf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Borderline_SMOTE(train_x_df, train_y_df):\n",
    "    x_b_smote, y_b_smote = BorderlineSMOTE().fit_resample(train_x_df, train_y_df)\n",
    "    return x_b_smote, y_b_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6e18",
   "metadata": {},
   "source": [
    "#### RandomOverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cb776b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:50, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5301796180752505 ~ 0.8287868354609178\n",
      "mean : 0.6706828915230093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Randomoversampler(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a0f11",
   "metadata": {},
   "source": [
    "#### SMOTE_ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb7cd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:04, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4748017083587553 ~ 0.6831617942729054\n",
      "mean : 0.5846311983159844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_ENN(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac5a5",
   "metadata": {},
   "source": [
    "#### SMOTE_Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d857227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:31, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5595878136200716 ~ 0.7641108495283818\n",
      "mean : 0.6652897385505305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_Tomek(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b428a",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c002771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:18, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569729683960966 ~ 0.763031391990668\n",
      "mean : 0.6790796785060819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d612d",
   "metadata": {},
   "source": [
    "#### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9122ab3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:32, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5720253529242293 ~ 0.788464737192282\n",
      "mean : 0.6945455511397514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Borderline_SMOTE(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09010b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c2475ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.to_csv('train_x_pp.csv', index=False)\n",
    "# train_y.to_csv('train_y_pp.csv', index=False)\n",
    "# test.to_csv('test_pp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "badcdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_objective(trial):\n",
    "\n",
    "    params = {\n",
    "            'iterations':trial.suggest_int(\"iterations\", 500, 3000),\n",
    "            'objective':trial.suggest_categorical('objective',['MultiClass']),\n",
    "            #'bootstrap_type':trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "            'od_wait':trial.suggest_int('od_wait', 500, 1000),\n",
    "            'learning_rate' : trial.suggest_uniform('learning_rate',0.01,1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
    "            'random_strength': trial.suggest_uniform('random_strength',20,50),\n",
    "            'depth': trial.suggest_int('depth',1,15),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,20),\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
    "            'verbose': False,\n",
    "            \"eval_metric\":'TotalF1',\n",
    "            #\"cat_features\" : ['PRODUCT_CODE', 'LINE'],\n",
    "            \"one_hot_max_size\": trial.suggest_int(\"one_hot_max_size\",1,5),\n",
    "            'task_type' : 'GPU',\n",
    "            #'thread_count': 5,\n",
    "        }\n",
    "\n",
    "#     if params['bootstrap_type'] == 'Bayesian':\n",
    "#         params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "#     elif params['bootstrap_type'] == 'Bernoulli':\n",
    "#         params['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "    \n",
    "    rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "    clf = catboost.CatBoostClassifier(**params)\n",
    "\n",
    "    f1_list = []\n",
    "    for fold, (train_index, val_index) in enumerate(rskfold.split(train_x, train_y)):\n",
    "        x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "        x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "        \n",
    "        clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "        f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "        print(1)\n",
    "    \n",
    "    return np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d785ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-17 01:19:40,193]\u001b[0m A new study created in memory with name: no-name-333da0bb-b053-46ac-87ff-d36dc825c2c1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010881423950195312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84391f56ffcc47559e016054a91e3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(cb_objective, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69fdc5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1337,\n",
       " 'objective': 'MultiClass',\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'od_wait': 552,\n",
       " 'learning_rate': 0.6128454724915484,\n",
       " 'reg_lambda': 77.08090755141544,\n",
       " 'random_strength': 43.1413895840195,\n",
       " 'depth': 3,\n",
       " 'min_data_in_leaf': 20,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'one_hot_max_size': 1,\n",
       " 'bagging_temperature': 0.06040383536784377}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(study.best_trial)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f303d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = catboost.CatBoostClassifier(**study.best_params, verbose=0).fit(train_x, train_y)\n",
    "pred = clf.predict(test)\n",
    "subm['Y_Class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cafef374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    264\n",
       "0     39\n",
       "2      7\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.Y_Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "680aa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('./submission_36_feat_del.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
