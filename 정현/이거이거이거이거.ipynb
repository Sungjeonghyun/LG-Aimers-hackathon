{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7efeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Permutation Importance & Visualization\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Scikit - learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Data Scaling\n",
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Model & AutoML\n",
    "import catboost\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe1223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature importance 무한히 돌리기\n",
    "### threshold\n",
    "\n",
    "# corr 그래프 등 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee207fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(37) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bb4982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "subm = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87a392cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "      <th>Y_Quality</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "      <th>X_2872</th>\n",
       "      <th>X_2873</th>\n",
       "      <th>X_2874</th>\n",
       "      <th>X_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>2022-06-13 5:14</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541819</td>\n",
       "      <td>2022-06-13 5:22</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>2022-06-13 5:30</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537325</td>\n",
       "      <td>2022-06-13 5:39</td>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531590</td>\n",
       "      <td>2022-06-13 5:47</td>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PRODUCT_ID  Y_Class  Y_Quality        TIMESTAMP     LINE PRODUCT_CODE  X_1  \\\n",
       "0  TRAIN_000        1   0.533433  2022-06-13 5:14  T050304         A_31  NaN   \n",
       "1  TRAIN_001        2   0.541819  2022-06-13 5:22  T050307         A_31  NaN   \n",
       "2  TRAIN_002        1   0.531267  2022-06-13 5:30  T050304         A_31  NaN   \n",
       "3  TRAIN_003        2   0.537325  2022-06-13 5:39  T050307         A_31  NaN   \n",
       "4  TRAIN_004        1   0.531590  2022-06-13 5:47  T050304         A_31  NaN   \n",
       "\n",
       "   X_2  X_3  X_4  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
       "0  NaN  NaN  NaN  ...   39.34   40.89   32.56   34.09   77.77     NaN     NaN   \n",
       "1  NaN  NaN  NaN  ...   38.89   42.82   43.92   35.34   72.55     NaN     NaN   \n",
       "2  NaN  NaN  NaN  ...   39.19   36.65   42.47   36.53   78.35     NaN     NaN   \n",
       "3  NaN  NaN  NaN  ...   37.74   39.17   52.17   30.58   71.78     NaN     NaN   \n",
       "4  NaN  NaN  NaN  ...   38.70   41.89   46.93   33.09   76.97     NaN     NaN   \n",
       "\n",
       "   X_2873  X_2874  X_2875  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 2881 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a79dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['PRODUCT_CODE'] = train['PRODUCT_CODE'].astype('category')\n",
    "train['LINE'] = train['LINE'].astype('category')\n",
    "\n",
    "test['PRODUCT_CODE'] = test['PRODUCT_CODE'].astype('category')\n",
    "test['LINE'] = test['LINE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8bfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 열의 유일한 값이 nan이거나 모두 같은 값인 경우 해당 열을 제외\n",
    "def remove_col(train_df, test_df):\n",
    "    for x in train_df.columns[6:]:\n",
    "        if train_df[x].nunique()==0 or (train_df[x].nunique()==1 and len(train_df[x].unique())==1): # nan 이거나 모두 같은 값인 경우\n",
    "            train_df.drop(columns=[x], inplace=True)\n",
    "            test_df.drop(columns=[x], inplace=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30fd903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = remove_col(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b596197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Quality'], inplace=True)\n",
    "\n",
    "test = test[train.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a62fbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train.drop(columns=['Y_Class']), train['Y_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6689b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE</th>\n",
       "      <th>PRODUCT_CODE</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_2862</th>\n",
       "      <th>X_2863</th>\n",
       "      <th>X_2864</th>\n",
       "      <th>X_2865</th>\n",
       "      <th>X_2866</th>\n",
       "      <th>X_2867</th>\n",
       "      <th>X_2868</th>\n",
       "      <th>X_2869</th>\n",
       "      <th>X_2870</th>\n",
       "      <th>X_2871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>368.296296</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.34</td>\n",
       "      <td>40.89</td>\n",
       "      <td>32.56</td>\n",
       "      <td>34.09</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>185.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.735849</td>\n",
       "      <td>353.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.92</td>\n",
       "      <td>35.34</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.5</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.320755</td>\n",
       "      <td>353.0</td>\n",
       "      <td>39.19</td>\n",
       "      <td>36.65</td>\n",
       "      <td>42.47</td>\n",
       "      <td>36.53</td>\n",
       "      <td>78.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T050307</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165.8</td>\n",
       "      <td>384.0</td>\n",
       "      <td>369.188679</td>\n",
       "      <td>353.0</td>\n",
       "      <td>37.74</td>\n",
       "      <td>39.17</td>\n",
       "      <td>52.17</td>\n",
       "      <td>30.58</td>\n",
       "      <td>71.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T050304</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>182.6</td>\n",
       "      <td>383.0</td>\n",
       "      <td>367.351852</td>\n",
       "      <td>352.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>41.89</td>\n",
       "      <td>46.93</td>\n",
       "      <td>33.09</td>\n",
       "      <td>76.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LINE PRODUCT_CODE  X_1  X_2  X_3  X_4  X_5  X_6  X_7  X_8  ...  X_2862  \\\n",
       "0  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   189.0   \n",
       "1  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   185.6   \n",
       "2  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.5   \n",
       "3  T050307         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   165.8   \n",
       "4  T050304         A_31  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   182.6   \n",
       "\n",
       "   X_2863      X_2864  X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \n",
       "0   383.0  368.296296   353.0   39.34   40.89   32.56   34.09   77.77     NaN  \n",
       "1   383.0  367.735849   353.0   38.89   42.82   43.92   35.34   72.55     NaN  \n",
       "2   383.0  367.320755   353.0   39.19   36.65   42.47   36.53   78.35     NaN  \n",
       "3   384.0  369.188679   353.0   37.74   39.17   52.17   30.58   71.78     NaN  \n",
       "4   383.0  367.351852   352.0   38.70   41.89   46.93   33.09   76.97     NaN  \n",
       "\n",
       "[5 rows x 2795 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2555d",
   "metadata": {},
   "source": [
    "### catboost cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a908d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9c4025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [06:01, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5811609030761885 : [0.14285714 0.68067227 0.68067227] ~ 0.7829945233454004 : [0.14285714 0.68067227 0.68067227]\n",
      "mean : 0.6609634746016518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6de3cb",
   "metadata": {},
   "source": [
    "### Feature & Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cca278",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c06f211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "clf.fit(train_x, train_y, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE'])\n",
    "\n",
    "feat = clf.feature_importances_\n",
    "feature_imp = pd.Series(feat, index=train_x.columns).sort_values(ascending=False)[:20].sort_values()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 15)\n",
    "plt.barh(feature_imp.index, feature_imp)\n",
    "plt.title('Feature_importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b9d6a22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_121</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_256</th>\n",
       "      <th>X_718</th>\n",
       "      <th>X_373</th>\n",
       "      <th>...</th>\n",
       "      <th>X_1440</th>\n",
       "      <th>X_1888</th>\n",
       "      <th>X_1758</th>\n",
       "      <th>X_1940</th>\n",
       "      <th>X_2105</th>\n",
       "      <th>X_394</th>\n",
       "      <th>X_1832</th>\n",
       "      <th>X_1936</th>\n",
       "      <th>X_1924</th>\n",
       "      <th>X_1762</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.706138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.414252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>0.07315</td>\n",
       "      <td>1.159383</td>\n",
       "      <td>0.149803</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.363817</td>\n",
       "      <td>0.091822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2267.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.749829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.418331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.149621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.416721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.418331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>13.351613</td>\n",
       "      <td>10.09</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.967742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.679252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.410926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.649743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.422233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>13.406667</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.633333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>13.380000</td>\n",
       "      <td>10.09</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.266667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_932   X_73     X_835  X_318  X_258  X_121  X_248  X_256      X_718  \\\n",
       "0          NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "1          NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "2          NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "3          NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "4          NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "..         ...    ...       ...    ...    ...    ...    ...    ...        ...   \n",
       "593  13.351613  10.09  9.096774    NaN    NaN   34.1    NaN    NaN  16.967742   \n",
       "594        NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "595        NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN        NaN   \n",
       "596  13.406667  10.22  9.533333    NaN    NaN   33.7    NaN    NaN  18.633333   \n",
       "597  13.380000  10.09  9.033333    NaN    NaN   34.1    NaN    NaN  18.266667   \n",
       "\n",
       "     X_373  ...  X_1440   X_1888    X_1758    X_1940    X_2105  X_394  \\\n",
       "0      NaN  ...  2269.0  0.00000  0.706138  0.000000  0.000008    NaN   \n",
       "1      NaN  ...  2270.0  0.07315  1.159383  0.149803  0.000003    NaN   \n",
       "2      NaN  ...  2267.0  0.00000  0.749829  0.000000  0.000009    NaN   \n",
       "3      NaN  ...  2268.0  0.00000  1.149621  0.000000  0.000002    NaN   \n",
       "4      NaN  ...  2271.0  0.00000  0.676211  0.000000  0.000008    NaN   \n",
       "..     ...  ...     ...      ...       ...       ...       ...    ...   \n",
       "593    NaN  ...     NaN      NaN       NaN       NaN       NaN  -60.0   \n",
       "594    NaN  ...  2296.0  0.00000  0.679252  0.000000       NaN    NaN   \n",
       "595    NaN  ...  2294.0  0.00000  0.649743  0.000000       NaN    NaN   \n",
       "596    NaN  ...     NaN      NaN       NaN       NaN       NaN  -20.0   \n",
       "597    NaN  ...     NaN      NaN       NaN       NaN       NaN  -10.0   \n",
       "\n",
       "       X_1832    X_1936  X_1924    X_1762  \n",
       "0    1.414252  0.000000     0.0  0.036773  \n",
       "1    1.363817  0.091822     0.0  0.062509  \n",
       "2    1.418331  0.000000     0.0  0.030454  \n",
       "3    1.416721  0.000000     0.0  0.064830  \n",
       "4    1.418331  0.000000     0.0  0.029483  \n",
       "..        ...       ...     ...       ...  \n",
       "593       NaN       NaN     NaN       NaN  \n",
       "594  1.410926  0.000000     0.0  0.019844  \n",
       "595  1.422233  0.000000     0.0  0.027558  \n",
       "596       NaN       NaN     NaN       NaN  \n",
       "597       NaN       NaN     NaN       NaN  \n",
       "\n",
       "[598 rows x 978 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_importance > 0 인 컬럼만 선택\n",
    "tmp = pd.Series(feat[feat > 0], index=train_x.columns[feat > 0]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44979b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col cnt : 800\n",
      "col cnt : 710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# while 1:\n",
    "#     clf = catboost.CatBoostClassifier(verbose=0, task_type='GPU') # cpu -> thread_count=5\n",
    "#     clf.fit(train_x, train_y, early_stopping_rounds=100)\n",
    "    \n",
    "#     feat = clf.feature_importances_\n",
    "#     tmp = pd.Series(feat[feat > 0], index=train_x.columns[feat > 0]).sort_values(ascending=False)[:]\n",
    "#     if len(tmp) == len(train_x.columns):\n",
    "#         break\n",
    "#     print('col cnt :', len(tmp))\n",
    "#     train_x = train_x[tmp.index]\n",
    "# test = test[train_x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1da4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:56, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6195245919596889 ~ 0.7974871547848427\n",
      "mean : 0.6965416058252865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "class_rate = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    class_rate.append(np.array([len(y_val[y_val==0]), len(y_val[y_val==1]), len(y_val[y_val==1])]) / len(y_val))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6637f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ceba74ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7665665665665666\n",
      "0.688506923129391\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for proba in clf.predict_proba(x_val):\n",
    "    if list(proba).index(max(proba)) == 1 and max(proba) < 0.7:\n",
    "        if proba[0] > proba[2]: \n",
    "            pred.append(0)\n",
    "        elif proba[0] < proba[2]:\n",
    "            pred.append(2)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    else:\n",
    "        pred.append(list(proba).index(max(proba)))\n",
    "        \n",
    "print(f1_score(pred, y_val, average='macro'))\n",
    "\n",
    "print(f1_score(clf.predict(x_val), y_val, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list, f1t_list = [], []\n",
    "cnt = 0\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    \n",
    "    threshold = 0.5 # 0.6->22 0.686, 0.65 -> 17, 0.75 -> 14, 0.7 -> 16\n",
    "    pred = []\n",
    "    for proba in clf.predict_proba(x_val):\n",
    "        if list(proba).index(max(proba)) == 1 and max(proba) < threshold:\n",
    "            if proba[0] > proba[2]: \n",
    "                pred.append(0)\n",
    "            elif proba[0] < proba[2]:\n",
    "                pred.append(2)\n",
    "            else:\n",
    "                pred.append(1)\n",
    "        else:\n",
    "            pred.append(list(proba).index(max(proba)))\n",
    "\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    f1t_list.append(f1_score(pred, y_val, average='macro'))\n",
    "    if f1_score(pred, y_val, average='macro') >= f1_score(clf.predict(x_val), y_val, average='macro'):\n",
    "        cnt += 1\n",
    "\n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))\n",
    "print()\n",
    "\n",
    "print(cnt, '/ 25')\n",
    "print(f'{min(f1t_list)} ~ {max(f1t_list)}')\n",
    "print('mean :', np.mean(f1t_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3f59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04955da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b31d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fce636c",
   "metadata": {},
   "source": [
    "#### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fa902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance는 영향력을 확인하는 것이다. column이 매우 많은 상황에서 score에 대한 영향력을 확인하는 것도 좋지만,\n",
    "# 결측치가 많고, test set에서 해당 columns이 어떤 상황일지 모르는 데 이 과정을 통해 column을 제거하는 것은 부정적인 영향을 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4399718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = [\"X_368\", \"X_367\", \"X_248\", \"X_73\", \"X_1569\", \"X_258\", \"X_318\", \"X_932\", \"X_380\", \"X_993\", \"X_1665\", \"X_1518\", \"X_899\", \"X_121\", \"X_1812\", \"X_1697\", \"X_1330\", \"X_1108\", \"X_1333\", \"X_120\", \"X_968\", \"X_1135\", \"X_1560\", \"X_1155\", \"X_1033\", \"X_556\", \"X_848\", \"X_1433\", \"X_517\", \"X_1346\", \"X_1202\", \"X_423\", \"X_1716\", \"X_718\", \"X_354\", \"X_1089\", \"X_497\", \"X_1473\", \"X_571\", \"X_2862\", \"X_983\", \"X_838\", \"X_374\", \"X_790\", \"X_1406\", \"X_942\", \"X_1378\", \"X_1214\", \"X_1424\", \"X_1172\", \"X_1129\", \"X_1122\", \"X_662\", \"X_1101\", \"X_985\", \"X_967\", \"X_815\", \"X_1058\", \"X_956\", \"X_1054\", \"X_1047\", \"X_1076\", \"X_1292\", \"X_2432\", \"X_346\", \"X_2791\", \"X_1610\", \"X_2794\", \"X_475\", \"X_2780\", \"X_286\", \"X_189\", \"X_256\", \"X_462\", \"X_62\", \"X_1389\", \"X_484\", \"X_388\", \"X_1350\", \"X_1740\", \"X_1471\", \"X_792\", \"X_949\", \"X_1509\", \"X_788\", \"X_1081\", \"X_1082\", \"X_963\", \"X_1373\", \"X_1631\", \"X_915\", \"X_997\", \"X_678\", \"X_1107\", \"X_422\", \"X_1335\", \"X_618\", \"X_1240\", \"X_1231\", \"X_1696\", \"X_995\", \"X_1557\", \"X_437\", \"X_1343\", \"X_1743\", \"X_1176\", \"X_90\", \"X_1647\", \"X_994\", \"X_825\", \"X_1512\", \"X_927\", \"X_1094\", \"X_926\", \"X_257\", \"X_1116\", \"X_397\", \"X_345\", \"X_894\", \"X_1211\", \"X_460\", \"X_1365\", \"X_810\", \"X_536\", \"X_1492\", \"X_2048\", \"X_1640\", \"X_574\", \"X_491\", \"X_660\", \"X_1351\", \"X_339\", \"X_651\", \"X_287\", \"X_616\", \"X_379\", \"X_668\", \"X_1366\", \"X_1532\", \"X_1642\", \"X_1213\", \"X_1551\", \"X_49\", \"X_1260\", \"X_1169\", \"X_1636\", \"X_820\", \"X_1059\", \"X_780\", \"X_2026\", \"X_2050\", \"X_490\", \"X_679\", \"X_661\", \"X_492\", \"X_581\", \"X_1416\", \"X_495\", \"X_2096\", \"X_553\", \"X_552\", \"X_1421\", \"X_506\", \"X_795\", \"X_706\", \"X_1548\", \"X_1048\", \"X_457\", \"X_901\", \"X_918\", \"X_922\", \"X_1530\", \"X_533\", \"X_897\", \"X_2702\", \"X_418\", \"X_417\", \"X_1752\", \"X_613\", \"X_982\", \"X_373\", \"X_1744\", \"X_1353\", \"X_1616\", \"X_698\", \"X_456\", \"X_1149\", \"X_1026\", \"X_45\", \"X_61\", \"X_2797\", \"X_529\", \"X_266\", \"X_712\", \"X_439\", \"X_603\", \"X_1243\", \"X_546\", \"X_2542\", \"X_1638\", \"X_2626\", \"X_2455\", \"X_2704\", \"X_2471\", \"X_2221\", \"X_2347\", \"X_2346\", \"X_2275\", \"X_2122\", \"X_2086\", \"X_2079\", \"X_2019\", \"X_1951\", \"X_1854\", \"X_1850\", \"X_1804\", \"X_1858\", \"X_984\", \"X_1475\", \"X_474\", \"X_667\", \"X_555\", \"X_544\", \"X_543\", \"X_539\", \"X_515\", \"X_502\", \"X_493\", \"X_468\", \"X_714\", \"X_465\", \"X_448\", \"X_436\", \"X_265\", \"X_139\", \"X_126\", \"X_110\", \"X_101\", \"X_1289\", \"X_710\", \"X_769\", \"X_1127\", \"X_1275\", \"X_819\", \"X_827\", \"X_1205\", \"X_855\", \"X_22\", \"X_1163\", \"X_1063\", \"X_791\", \"X_1111\", \"X_1112\", \"X_1113\", \"X_1114\", \"X_1014\", \"X_2467\", \"X_12\", \"X_1179\", \"X_835\", \"X_572\", \"X_1000\"]\n",
    "# train_x = train_x[col]\n",
    "# test_x = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "661c6ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:31:27, 1817.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0252\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1743\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_932\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_367\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1744\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0126\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_368\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_121\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0151\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_120\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0118\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_73\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1569\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1716\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_571\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_318\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_248\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_516\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_1033\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_62\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0067\n",
       "                \n",
       "                    &plusmn; 0.0067\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_462\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0050\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_651\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0034\n",
       "                \n",
       "                    &plusmn; 0.0082\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                X_258\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 2775 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=1)\n",
    "\n",
    "perm_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100, cat_features=['PRODUCT_CODE', 'LINE']) # Feature_importance에서 LINE이 제거됨\n",
    "\n",
    "    perm = PermutationImportance(clf).fit(x_val, y_val) # n_iter = 1\n",
    "    perm_list.append(perm.feature_importances_)\n",
    "    \n",
    "eli5.show_weights(perm, feature_names = x_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3082ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_368</th>\n",
       "      <th>X_367</th>\n",
       "      <th>X_248</th>\n",
       "      <th>X_73</th>\n",
       "      <th>X_1569</th>\n",
       "      <th>X_258</th>\n",
       "      <th>X_318</th>\n",
       "      <th>X_932</th>\n",
       "      <th>X_380</th>\n",
       "      <th>X_993</th>\n",
       "      <th>...</th>\n",
       "      <th>X_1112</th>\n",
       "      <th>X_1113</th>\n",
       "      <th>X_1114</th>\n",
       "      <th>X_1014</th>\n",
       "      <th>X_2467</th>\n",
       "      <th>X_12</th>\n",
       "      <th>X_1179</th>\n",
       "      <th>X_835</th>\n",
       "      <th>X_572</th>\n",
       "      <th>X_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.925926</td>\n",
       "      <td>84.111111</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>404.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.981132</td>\n",
       "      <td>84.396226</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>395.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.645161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.018868</td>\n",
       "      <td>84.018868</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>407.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.531250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.962264</td>\n",
       "      <td>84.320755</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>397.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.935484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.111111</td>\n",
       "      <td>85.203704</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.351613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>473.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.096774</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.612903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.056604</td>\n",
       "      <td>85.037736</td>\n",
       "      <td>3.418868</td>\n",
       "      <td>419.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>212.132076</td>\n",
       "      <td>84.792453</td>\n",
       "      <td>3.433962</td>\n",
       "      <td>428.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>510.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>474.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.033333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_368  X_367  X_248   X_73      X_1569  X_258  X_318      X_932  X_380  \\\n",
       "0      NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    0.0   \n",
       "1      NaN    NaN    NaN    NaN  486.593750    NaN    NaN        NaN    0.0   \n",
       "2      NaN    NaN    NaN    NaN  486.645161    NaN    NaN        NaN    0.0   \n",
       "3      NaN    NaN    NaN    NaN  486.531250    NaN    NaN        NaN    0.0   \n",
       "4      NaN    NaN    NaN    NaN  486.935484    NaN    NaN        NaN    0.0   \n",
       "..     ...    ...    ...    ...         ...    ...    ...        ...    ...   \n",
       "593    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.351613    NaN   \n",
       "594    NaN    NaN    NaN    NaN  486.612903    NaN    NaN        NaN    3.0   \n",
       "595    NaN    NaN    NaN    NaN  486.677419    NaN    NaN        NaN    3.0   \n",
       "596    NaN    NaN    NaN  10.22         NaN    NaN    NaN  13.406667    NaN   \n",
       "597    NaN    NaN    NaN  10.09         NaN    NaN    NaN  13.380000    NaN   \n",
       "\n",
       "     X_993  ...      X_1112     X_1113    X_1114  X_1014  X_2467   X_12  \\\n",
       "0    102.0  ...  211.925926  84.111111  3.500000   404.0    35.0    NaN   \n",
       "1    103.0  ...  211.981132  84.396226  3.500000   395.0    36.0    NaN   \n",
       "2    103.0  ...  212.018868  84.018868  3.500000   407.0    34.7    NaN   \n",
       "3    104.0  ...  211.962264  84.320755  3.500000   397.0    35.8    NaN   \n",
       "4    109.0  ...  212.111111  85.203704  3.500000   420.0    34.6    NaN   \n",
       "..     ...  ...         ...        ...       ...     ...     ...    ...   \n",
       "593    NaN  ...         NaN        NaN       NaN     NaN     NaN  473.9   \n",
       "594  296.0  ...  212.056604  85.037736  3.418868   419.0    35.6    NaN   \n",
       "595  298.0  ...  212.132076  84.792453  3.433962   428.0    35.6    NaN   \n",
       "596    NaN  ...         NaN        NaN       NaN     NaN     NaN  510.9   \n",
       "597    NaN  ...         NaN        NaN       NaN     NaN     NaN  474.9   \n",
       "\n",
       "     X_1179     X_835  X_572  X_1000  \n",
       "0      20.0       NaN    NaN   411.0  \n",
       "1      21.0       NaN    NaN   414.0  \n",
       "2      22.0       NaN    NaN   417.0  \n",
       "3      22.0       NaN    NaN   421.0  \n",
       "4      22.0       NaN    NaN   441.0  \n",
       "..      ...       ...    ...     ...  \n",
       "593     NaN  9.096774   21.0     NaN  \n",
       "594    23.0       NaN    NaN  1384.0  \n",
       "595    21.0       NaN    NaN  1393.0  \n",
       "596     NaN  9.533333   20.0     NaN  \n",
       "597     NaN  9.033333   21.0     NaN  \n",
       "\n",
       "[598 rows x 262 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_list = np.array(perm_list)\n",
    "perm_mean = np.array([np.mean(perm_list[:, i]) for i in range(len(perm_list[0]))])\n",
    "tmp = pd.Series(perm_mean[(perm_mean > 0)], index=train_x.columns[(perm_mean > 0)]).sort_values(ascending=False)[:]\n",
    "train_x = train_x[tmp.index]\n",
    "test = test[train_x.columns]\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d077a895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:27, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639344766119614 : [0.15       0.68333333 0.68333333] ~ 0.8053274949826674 : [0.15       0.68333333 0.68333333]\n",
      "mean : 0.7111273645948281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5, gpu -> task_type=\"GPU\"\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892d185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92008858",
   "metadata": {},
   "source": [
    "### 결측치 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad362d",
   "metadata": {},
   "source": [
    "#### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10d54956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df292fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:57, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5946844319775596 ~ 0.7632555715889048\n",
      "mean : 0.6956812485682076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c296",
   "metadata": {},
   "source": [
    "### Data Scaling (random, SMOTE ENN, SMOTE Tomek, ADASYN, Borderline SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d8790e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomoversampler(train_x_df, train_y_df):\n",
    "    x_ros, y_ros = RandomOverSampler().fit_resample(train_x_df, train_y_df)\n",
    "    return x_ros, y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720865d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_Tomek(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTETomek().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3fd930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_ENN(train_x_df, train_y_df):\n",
    "    x_smoteenn, y_smoteenn = SMOTEENN().fit_resample(train_x_df, train_y_df)\n",
    "    return x_smoteenn, y_smoteenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bed1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADASYN_(train_x_df, train_y_df):\n",
    "    x_adasyn, y_adasyn = ADASYN(sampling_strategy='minority').fit_resample(train_x_df, train_y_df)\n",
    "    return x_adasyn, y_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cecbf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Borderline_SMOTE(train_x_df, train_y_df):\n",
    "    x_b_smote, y_b_smote = BorderlineSMOTE().fit_resample(train_x_df, train_y_df)\n",
    "    return x_b_smote, y_b_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6e18",
   "metadata": {},
   "source": [
    "#### RandomOverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cb776b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [04:50, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5301796180752505 ~ 0.8287868354609178\n",
      "mean : 0.6706828915230093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Randomoversampler(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a0f11",
   "metadata": {},
   "source": [
    "#### SMOTE_ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb7cd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:04, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4748017083587553 ~ 0.6831617942729054\n",
      "mean : 0.5846311983159844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_ENN(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffac5a5",
   "metadata": {},
   "source": [
    "#### SMOTE_Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d857227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:31, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5595878136200716 ~ 0.7641108495283818\n",
      "mean : 0.6652897385505305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = SMOTE_Tomek(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b428a",
   "metadata": {},
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c002771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:18, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569729683960966 ~ 0.763031391990668\n",
      "mean : 0.6790796785060819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d612d",
   "metadata": {},
   "source": [
    "#### BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9122ab3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:32, 13.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5720253529242293 ~ 0.788464737192282\n",
      "mean : 0.6945455511397514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "\n",
    "f1_list = []\n",
    "for fold, (train_index, val_index) in enumerate(tqdm(rskfold.split(train_x, train_y))):\n",
    "    x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "    x_trn, y_trn = Borderline_SMOTE(x_trn, y_trn)\n",
    "    \n",
    "    clf = catboost.CatBoostClassifier(verbose=0, task_type=\"GPU\") # cpu -> thread_count=5\n",
    "    clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "    f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "    \n",
    "print(f'{min(f1_list)} ~ {max(f1_list)}')\n",
    "print('mean :', np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09010b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c2475ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.to_csv('train_x_pp.csv', index=False)\n",
    "# train_y.to_csv('train_y_pp.csv', index=False)\n",
    "# test.to_csv('test_pp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e06c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "badcdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_objective(trial):\n",
    "\n",
    "    params = {\n",
    "            'iterations':trial.suggest_int(\"iterations\", 500, 3000),\n",
    "            'objective':trial.suggest_categorical('objective',['MultiClass']),\n",
    "            #'bootstrap_type':trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "            'od_wait':trial.suggest_int('od_wait', 500, 1000),\n",
    "            'learning_rate' : trial.suggest_uniform('learning_rate',0.01,1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
    "            'random_strength': trial.suggest_uniform('random_strength',20,50),\n",
    "            'depth': trial.suggest_int('depth',1,15),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,20),\n",
    "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
    "            'verbose': False,\n",
    "            \"eval_metric\":'TotalF1',\n",
    "            #\"cat_features\" : ['PRODUCT_CODE', 'LINE'],\n",
    "            \"one_hot_max_size\": trial.suggest_int(\"one_hot_max_size\",1,5),\n",
    "            'task_type' : 'GPU',\n",
    "            #'thread_count': 5,\n",
    "        }\n",
    "\n",
    "#     if params['bootstrap_type'] == 'Bayesian':\n",
    "#         params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "#     elif params['bootstrap_type'] == 'Bernoulli':\n",
    "#         params['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "    \n",
    "    rskfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "    clf = catboost.CatBoostClassifier(**params)\n",
    "\n",
    "    f1_list = []\n",
    "    for fold, (train_index, val_index) in enumerate(rskfold.split(train_x, train_y)):\n",
    "        x_trn, x_val, y_trn, y_val = train_x.loc[train_index], train_x.loc[val_index], train_y.loc[train_index], train_y.loc[val_index]\n",
    "        x_trn, y_trn = ADASYN_(x_trn, y_trn)\n",
    "        \n",
    "        clf.fit(x_trn, y_trn, early_stopping_rounds=100)\n",
    "        f1_list.append(f1_score(clf.predict(x_val), y_val, average='macro'))\n",
    "        print(1)\n",
    "    \n",
    "    return np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35d785ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-17 01:19:40,193]\u001b[0m A new study created in memory with name: no-name-333da0bb-b053-46ac-87ff-d36dc825c2c1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010881423950195312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 30,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84391f56ffcc47559e016054a91e3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(cb_objective, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69fdc5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1337,\n",
       " 'objective': 'MultiClass',\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'od_wait': 552,\n",
       " 'learning_rate': 0.6128454724915484,\n",
       " 'reg_lambda': 77.08090755141544,\n",
       " 'random_strength': 43.1413895840195,\n",
       " 'depth': 3,\n",
       " 'min_data_in_leaf': 20,\n",
       " 'leaf_estimation_iterations': 2,\n",
       " 'one_hot_max_size': 1,\n",
       " 'bagging_temperature': 0.06040383536784377}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(study.best_trial)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f303d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = catboost.CatBoostClassifier(**study.best_params, verbose=0).fit(train_x, train_y)\n",
    "pred = clf.predict(test)\n",
    "subm['Y_Class'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cafef374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    264\n",
       "0     39\n",
       "2      7\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm.Y_Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "680aa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv('./submission_36_feat_del.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
